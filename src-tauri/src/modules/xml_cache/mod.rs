use tauri::{plugin::{Builder, TauriPlugin}, Runtime};
use tracing::{info, warn, debug, error};
use serde::{Serialize, Deserialize};
use std::collections::HashMap;
use anyhow::Result;

// ğŸš€ Phase 2: å¼•å…¥ç¼“å­˜ç”Ÿå‘½å‘¨æœŸç®¡ç†
use crate::domain::analysis_cache::{
    lifecycle::{
        pin_snapshot, unpin_snapshot, get_snapshot_ref_info, get_all_snapshot_refs,
        validate_cache_consistency, force_clear_all_caches, SnapshotRefInfo
    },
    SnapshotId, SNAPSHOT_REFS, DOM_CACHE, SUBTREE_CACHE
};
use crate::domain::analysis_cache::api::{register_snapshot, get_or_compute_subtree, try_get_subtree};
use crate::domain::analysis_cache::types::SubtreeMetricsDto;

mod enhanced; // âœ… Add enhanced cache module

// ==================== ğŸ“ XML Cache Management ====================

/// ğŸ“¦ XMLç¼“å­˜æ–‡ä»¶å…ƒæ•°æ®ï¼ˆä¸€æ¬¡æ€§è¿”å›æ‰€æœ‰æ–‡ä»¶çš„å®Œæ•´ä¿¡æ¯ï¼‰
#[derive(Debug, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct XmlCacheFileMetadata {
    /// æ–‡ä»¶åï¼ˆå¦‚ ui_dump_e0d909c3_20251203_123223.xmlï¼‰
    pub file_name: String,
    /// æ–‡ä»¶ç»å¯¹è·¯å¾„
    pub absolute_path: String,
    /// æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
    pub file_size: u64,
    /// è®¾å¤‡IDï¼ˆä»æ–‡ä»¶åè§£æï¼‰
    pub device_id: String,
    /// æ—¶é—´æˆ³ï¼ˆä»æ–‡ä»¶åè§£æï¼Œæ ¼å¼å¦‚ 20251203_123223ï¼‰
    pub timestamp: String,
    /// æˆªå›¾æ–‡ä»¶åï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    pub screenshot_file_name: Option<String>,
    /// æˆªå›¾ç»å¯¹è·¯å¾„ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    pub screenshot_absolute_path: Option<String>,
    /// åº”ç”¨åŒ…åï¼ˆé€šè¿‡æ‰«æXMLå†…å®¹æ£€æµ‹ï¼‰
    pub app_package: String,
    /// é¡µé¢ç±»å‹ï¼ˆé€šè¿‡æ‰«æXMLå†…å®¹è¯†åˆ«ï¼‰
    pub page_type: String,
    /// å…ƒç´ æ•°é‡ï¼ˆé€šè¿‡ç»Ÿè®¡XMLèŠ‚ç‚¹ï¼‰
    pub element_count: u32,
    /// å¯ç‚¹å‡»å…ƒç´ æ•°é‡
    pub clickable_count: u32,
    /// é¡µé¢æè¿°
    pub description: String,
    /// ä¸»è¦æŒ‰é’®æ–‡æœ¬ï¼ˆæœ€å¤š8ä¸ªï¼‰
    pub main_buttons: Vec<String>,
    /// ä¸»è¦æ–‡æœ¬å†…å®¹ï¼ˆæœ€å¤š10ä¸ªï¼‰
    pub main_texts: Vec<String>,
    /// è¾“å…¥æ¡†æ•°é‡
    pub input_count: u32,
}

#[tauri::command]
async fn list_xml_cache_files() -> Result<Vec<String>, String> {
    use std::fs;
    let debug_dir = get_debug_xml_dir();
    if !debug_dir.exists() { return Ok(vec![]); }
    match fs::read_dir(&debug_dir) {
        Ok(entries) => {
            let mut xml_files = Vec::new();
            for entry in entries.flatten() {
                let path = entry.path();
                if path.is_file() { if let Some(name) = path.file_name().and_then(|f| f.to_str()) { if name.ends_with(".xml") && name.starts_with("ui_dump_") { xml_files.push(name.to_string()); } } }
            }
            xml_files.sort(); xml_files.reverse();
            Ok(xml_files)
        }
        Err(e) => Err(format!("è¯»å–debug_xmlç›®å½•å¤±è´¥: {}", e))
    }
}

/// ğŸš€ æ‰¹é‡è·å–æ‰€æœ‰XMLç¼“å­˜æ–‡ä»¶çš„å®Œæ•´å…ƒæ•°æ®ï¼ˆä¸€æ¬¡IPCè°ƒç”¨æ›¿ä»£ NÃ—4 æ¬¡è°ƒç”¨ï¼‰
/// 
/// ä¼˜åŒ–å‰ï¼šæ¯ä¸ªæ–‡ä»¶éœ€è¦ 4 æ¬¡ IPC è°ƒç”¨ï¼ˆlist + read + size + pathï¼‰
/// ä¼˜åŒ–åï¼šä¸€æ¬¡è°ƒç”¨è¿”å›æ‰€æœ‰æ–‡ä»¶çš„å®Œæ•´å…ƒæ•°æ®
#[tauri::command]
async fn list_xml_cache_files_with_metadata() -> Result<Vec<XmlCacheFileMetadata>, String> {
    use std::fs;
    use std::time::Instant;
    use regex::Regex;
    
    let start = Instant::now();
    let debug_dir = get_debug_xml_dir();
    
    if !debug_dir.exists() {
        info!("ğŸ“‚ debug_xml ç›®å½•ä¸å­˜åœ¨ï¼Œè¿”å›ç©ºåˆ—è¡¨");
        return Ok(vec![]);
    }
    
    let entries = fs::read_dir(&debug_dir)
        .map_err(|e| format!("è¯»å–debug_xmlç›®å½•å¤±è´¥: {}", e))?;
    
    // æ–‡ä»¶åæ­£åˆ™ï¼šui_dump_{deviceId}_{timestamp}.xml
    let filename_regex = Regex::new(r"^ui_dump_([^_]+)_(\d{8}_\d{6})\.xml$")
        .map_err(|e| format!("æ­£åˆ™ç¼–è¯‘å¤±è´¥: {}", e))?;
    
    let mut results = Vec::new();
    
    for entry in entries.flatten() {
        let path = entry.path();
        if !path.is_file() { continue; }
        
        let file_name = match path.file_name().and_then(|f| f.to_str()) {
            Some(name) if name.ends_with(".xml") && name.starts_with("ui_dump_") => name.to_string(),
            _ => continue,
        };
        
        // è§£ææ–‡ä»¶åè·å– deviceId å’Œ timestamp
        let (device_id, timestamp) = match filename_regex.captures(&file_name) {
            Some(caps) => (
                caps.get(1).map(|m| m.as_str().to_string()).unwrap_or_default(),
                caps.get(2).map(|m| m.as_str().to_string()).unwrap_or_default()
            ),
            None => {
                warn!("âš ï¸ æ— æ³•è§£ææ–‡ä»¶å: {}", file_name);
                continue;
            }
        };
        
        // è·å–æ–‡ä»¶å¤§å°
        let file_size = fs::metadata(&path)
            .map(|m| m.len())
            .unwrap_or(0);
        
        // è·å–ç»å¯¹è·¯å¾„
        let absolute_path = fs::canonicalize(&path)
            .map(|p| p.to_string_lossy().to_string())
            .unwrap_or_else(|_| path.to_string_lossy().to_string());
        
        // æ£€æŸ¥æˆªå›¾æ˜¯å¦å­˜åœ¨
        let screenshot_file_name = file_name.replace(".xml", ".png");
        let screenshot_path = debug_dir.join(&screenshot_file_name);
        let (screenshot_file_name, screenshot_absolute_path) = if screenshot_path.exists() {
            let abs_path = fs::canonicalize(&screenshot_path)
                .map(|p| p.to_string_lossy().to_string())
                .ok();
            (Some(screenshot_file_name), abs_path)
        } else {
            (None, None)
        };
        
        // è¯»å– XML å†…å®¹å¹¶åˆ†æ
        let xml_content = match fs::read_to_string(&path) {
            Ok(content) => content,
            Err(e) => {
                warn!("âš ï¸ è¯»å–æ–‡ä»¶å¤±è´¥ {}: {}", file_name, e);
                continue;
            }
        };
        
        // åˆ†æ XML å†…å®¹ï¼ˆä½¿ç”¨é«˜æ•ˆçš„æ­£åˆ™æ‰«æï¼Œé¿å…å®Œæ•´ DOM è§£æï¼‰
        let analysis = analyze_xml_content_fast(&xml_content);
        
        results.push(XmlCacheFileMetadata {
            file_name,
            absolute_path,
            file_size,
            device_id,
            timestamp,
            screenshot_file_name,
            screenshot_absolute_path,
            app_package: analysis.app_package,
            page_type: analysis.page_type,
            element_count: analysis.element_count,
            clickable_count: analysis.clickable_count,
            description: analysis.description,
            main_buttons: analysis.main_buttons,
            main_texts: analysis.main_texts,
            input_count: analysis.input_count,
        });
    }
    
    // æŒ‰æ—¶é—´æˆ³é™åºæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    results.sort_by(|a, b| b.timestamp.cmp(&a.timestamp));
    
    let elapsed = start.elapsed();
    info!("âœ… æ‰¹é‡åŠ è½½ {} ä¸ªXMLç¼“å­˜æ–‡ä»¶å…ƒæ•°æ®å®Œæˆï¼Œè€—æ—¶ {:?}", results.len(), elapsed);
    
    Ok(results)
}

/// å¿«é€Ÿåˆ†æ XML å†…å®¹ï¼ˆä½¿ç”¨æ­£åˆ™è€Œé DOM è§£æï¼Œæå‡æ€§èƒ½ï¼‰
struct XmlAnalysisResult {
    app_package: String,
    page_type: String,
    element_count: u32,
    clickable_count: u32,
    description: String,
    main_buttons: Vec<String>,
    main_texts: Vec<String>,
    input_count: u32,
}

fn analyze_xml_content_fast(xml_content: &str) -> XmlAnalysisResult {
    use regex::Regex;
    
    // æ£€æµ‹åº”ç”¨åŒ…åï¼ˆé«˜æ•ˆå­—ç¬¦ä¸²æœç´¢ï¼‰
    let app_package = if xml_content.contains("com.xingin.xhs") {
        "com.xingin.xhs".to_string()
    } else if xml_content.contains("com.tencent.mm") {
        "com.tencent.mm".to_string()
    } else if xml_content.contains("com.ss.android.ugc.aweme") {
        "com.ss.android.ugc.aweme".to_string()
    } else if xml_content.contains("com.android.contacts") {
        "com.android.contacts".to_string()
    } else {
        "unknown".to_string()
    };
    
    // ç»Ÿè®¡å…ƒç´ æ•°é‡ï¼ˆç»Ÿè®¡ <node å‡ºç°æ¬¡æ•°ï¼‰
    let element_count = xml_content.matches("<node ").count() as u32;
    
    // ç»Ÿè®¡å¯ç‚¹å‡»å…ƒç´ ï¼ˆç»Ÿè®¡ clickable="true" å‡ºç°æ¬¡æ•°ï¼‰
    let clickable_count = xml_content.matches(r#"clickable="true""#).count() as u32;
    
    // ç»Ÿè®¡è¾“å…¥æ¡†ï¼ˆç»Ÿè®¡ EditText å‡ºç°æ¬¡æ•°ï¼‰
    let input_count = xml_content.matches("EditText").count() as u32;
    
    // æå–ä¸»è¦æ–‡æœ¬ï¼ˆæ­£åˆ™åŒ¹é… text="..."ï¼‰
    let text_regex = Regex::new(r#"text="([^"]{1,20})""#).unwrap();
    let main_texts: Vec<String> = text_regex.captures_iter(xml_content)
        .filter_map(|cap| cap.get(1).map(|m| m.as_str().trim().to_string()))
        .filter(|s| !s.is_empty())
        .take(10)
        .collect();
    
    // æå–å¯ç‚¹å‡»å…ƒç´ çš„æ–‡æœ¬ä½œä¸ºä¸»è¦æŒ‰é’®
    // ç®€åŒ–ï¼šåŒ¹é… clickable="true" å‰åçš„ text å±æ€§
    let button_regex = Regex::new(r#"text="([^"]{1,15})"[^>]*clickable="true"|clickable="true"[^>]*text="([^"]{1,15})""#).unwrap();
    let main_buttons: Vec<String> = button_regex.captures_iter(xml_content)
        .filter_map(|cap| {
            cap.get(1).or_else(|| cap.get(2))
                .map(|m| m.as_str().trim().to_string())
        })
        .filter(|s| !s.is_empty())
        .take(8)
        .collect();
    
    // è¯†åˆ«é¡µé¢ç±»å‹
    let page_type = identify_page_type_fast(&app_package, xml_content);
    
    // ç”Ÿæˆæè¿°
    let description = format!("{} â€¢ {}ä¸ªå¯ç‚¹å‡»å…ƒç´ ", page_type, clickable_count);
    
    XmlAnalysisResult {
        app_package,
        page_type,
        element_count,
        clickable_count,
        description,
        main_buttons,
        main_texts,
        input_count,
    }
}

fn identify_page_type_fast(app_package: &str, xml_content: &str) -> String {
    match app_package {
        "com.xingin.xhs" => {
            if xml_content.contains("å‘ç°") && xml_content.contains("é¦–é¡µ") {
                "å°çº¢ä¹¦é¦–é¡µ".to_string()
            } else if xml_content.contains("æœç´¢") {
                "å°çº¢ä¹¦æœç´¢é¡µ".to_string()
            } else if xml_content.contains("æ¶ˆæ¯") || xml_content.contains("èŠå¤©") {
                "å°çº¢ä¹¦æ¶ˆæ¯é¡µ".to_string()
            } else if xml_content.contains("ç²‰ä¸") || xml_content.contains("å…³æ³¨") {
                "å°çº¢ä¹¦ä¸ªäººä¸­å¿ƒ".to_string()
            } else if xml_content.contains("è¯„è®º") {
                "å°çº¢ä¹¦è¯¦æƒ…é¡µ".to_string()
            } else {
                "å°çº¢ä¹¦é¡µé¢".to_string()
            }
        }
        "com.tencent.mm" => "å¾®ä¿¡é¡µé¢".to_string(),
        "com.ss.android.ugc.aweme" => {
            if xml_content.contains("é¦–é¡µ") {
                "æŠ–éŸ³é¦–é¡µ".to_string()
            } else {
                "æŠ–éŸ³é¡µé¢".to_string()
            }
        }
        "com.android.contacts" => "ç³»ç»Ÿé€šè®¯å½•".to_string(),
        _ => "æœªçŸ¥é¡µé¢".to_string(),
    }
}

#[tauri::command]
async fn read_xml_cache_file(file_name: String) -> Result<String, String> {
    use std::fs;
    let debug_dir = get_debug_xml_dir();
    let file_path = debug_dir.join(&file_name);
    if !file_path.exists() { return Err(format!("XMLç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨: {}", file_name)); }
    fs::read_to_string(&file_path).map_err(|e| format!("è¯»å–XMLç¼“å­˜æ–‡ä»¶å¤±è´¥: {} - {}", file_name, e))
}

#[tauri::command]
async fn get_xml_file_size(file_name: String) -> Result<u64, String> {
    use std::fs;
    let debug_dir = get_debug_xml_dir();
    let file_path = debug_dir.join(&file_name);
    if !file_path.exists() { return Err(format!("XMLç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨: {}", file_name)); }
    fs::metadata(&file_path).map(|m| m.len()).map_err(|e| format!("è·å–æ–‡ä»¶å¤§å°å¤±è´¥: {} - {}", file_name, e))
}

#[tauri::command]
async fn get_xml_file_absolute_path(file_name: String) -> Result<String, String> {
    use std::fs;
    // åŸæœ‰é€»è¾‘ï¼šä¼˜å…ˆä½¿ç”¨çˆ¶ç›®å½•çš„ debug_xml
    let primary_debug_dir = get_debug_xml_dir();
    let primary_file_path = primary_debug_dir.join(&file_name);

    // å›é€€é€»è¾‘ï¼šæŸäº›è¿è¡Œæ–¹å¼ä¸‹ current_dir å¯èƒ½å°±æ˜¯é¡¹ç›®æ ¹ç›®å½•ï¼Œç›´æ¥å°è¯• ./debug_xml
    let fallback_debug_dir = std::env::current_dir()
        .unwrap_or_else(|_| std::path::PathBuf::from("."))
        .join("debug_xml");
    let fallback_file_path = fallback_debug_dir.join(&file_name);

    let (chosen_path, chosen_base) = if primary_file_path.exists() {
        (primary_file_path, "parent/debug_xml")
    } else if fallback_file_path.exists() {
        (fallback_file_path, "current/debug_xml")
    } else {
        return Err(format!("ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨: {} (å°è¯•äº: {} ä¸ {})",
            file_name,
            primary_debug_dir.display(),
            fallback_debug_dir.display()
        ));
    };

    info!("ğŸ“‚ è·å–ç¼“å­˜æ–‡ä»¶ç»å¯¹è·¯å¾„: [{}] {}", chosen_base, chosen_path.display());

    match fs::canonicalize(&chosen_path) {
        Ok(path) => Ok(path.to_string_lossy().to_string()),
        Err(err) => {
            info!("âš ï¸ canonicalizeå¤±è´¥ï¼Œå°†è¿”å›åŸè·¯å¾„: {} - {}", chosen_path.display(), err);
            Ok(chosen_path.to_string_lossy().to_string())
        }
    }
}

#[tauri::command]
async fn delete_xml_cache_artifacts(
    xml_file_name: String,
    screenshot_file_name: Option<String>,
) -> Result<(), String> {
    use std::fs;

    let debug_dir = get_debug_xml_dir();
    let xml_path = debug_dir.join(&xml_file_name);
    if !xml_path.exists() {
        return Err(format!("XMLç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨: {}", xml_file_name));
    }

    fs::remove_file(&xml_path)
        .map_err(|e| format!("åˆ é™¤XMLç¼“å­˜æ–‡ä»¶å¤±è´¥: {} - {}", xml_file_name, e))?;

    let screenshot_candidate = screenshot_file_name
        .filter(|name| !name.trim().is_empty())
        .unwrap_or_else(|| xml_file_name.replace(".xml", ".png"));

    if screenshot_candidate != xml_file_name {
        let screenshot_path = debug_dir.join(&screenshot_candidate);
        if screenshot_path.exists() {
            if let Err(err) = fs::remove_file(&screenshot_path) {
                warn!(
                    "âš ï¸ åˆ é™¤æˆªå›¾æ–‡ä»¶å¤±è´¥: {} - {}",
                    screenshot_path.display(),
                    err
                );
            } else {
                info!(
                    "ğŸ—‘ï¸ å·²åˆ é™¤å…³è”æˆªå›¾: {}",
                    screenshot_path.display()
                );
            }
        }
    }

    Ok(())
}

#[tauri::command]
async fn parse_cached_xml_to_elements(
    xml_content: Option<String>,
    file_path: Option<String>,
    enable_filtering: Option<bool>, // æ–°å¢å‚æ•°ï¼šæ˜¯å¦å¯ç”¨è¿‡æ»¤
) -> Result<serde_json::Value, String> {
    use crate::services::universal_ui_page_analyzer::UniversalUIPageAnalyzer;
    use tracing::{info, error};

    // é»˜è®¤ç¦ç”¨è¿‡æ»¤å™¨ï¼Œä»¥è·å–æ‰€æœ‰å…ƒç´ ç”¨äºå…ƒç´ å‘ç°
    let filtering_enabled = enable_filtering.unwrap_or(false);
    
    info!("ğŸ¯ å¼€å§‹è§£æXMLå†…å®¹åˆ°UIå…ƒç´  (è¿‡æ»¤å™¨: {})", if filtering_enabled { "å¯ç”¨" } else { "ç¦ç”¨" });

    // è·å–XMLå†…å®¹
    let xml_data = match (xml_content, file_path) {
        (Some(content), _) => content,
        (None, Some(path)) => {
            // è¯»å–ç¼“å­˜æ–‡ä»¶
            let cache_path = std::path::Path::new(&path);
            match std::fs::read_to_string(&cache_path) {
                Ok(content) => {
                    info!("âœ… ä»ç¼“å­˜æ–‡ä»¶è¯»å–XML: {} (é•¿åº¦: {})", path, content.len());
                    content
                }
                Err(e) => {
                    error!("âŒ è¯»å–XMLæ–‡ä»¶å¤±è´¥: {}", e);
                    return Err(format!("æ— æ³•è¯»å–XMLæ–‡ä»¶ {}: {}", path, e));
                }
            }
        }
        (None, None) => {
            error!("âŒ å¿…é¡»æä¾›xml_contentæˆ–file_pathå‚æ•°");
            return Err("å¿…é¡»æä¾›xml_contentæˆ–file_pathå‚æ•°".to_string());
        }
    };

    info!("ğŸ“„ XMLå†…å®¹é•¿åº¦: {} å­—ç¬¦", xml_data.len());

    // ä½¿ç”¨ç»Ÿä¸€çš„è§£æå™¨ï¼Œæ ¹æ®å‚æ•°å†³å®šæ˜¯å¦è¿‡æ»¤
    let analyzer = UniversalUIPageAnalyzer::new();
    
    match analyzer.parse_xml_elements(&xml_data, filtering_enabled) {
        Ok(elements) => {
            let count = elements.len();
            info!("âœ… æˆåŠŸæå– {} ä¸ªUIå…ƒç´  (è¿‡æ»¤: {})", count, if filtering_enabled { "æ˜¯" } else { "å¦" });
            
            // è½¬æ¢ä¸ºJSONæ ¼å¼
            match serde_json::to_value(elements) {
                Ok(json_elements) => {
                    info!("ğŸ‰ XMLè§£æå®Œæˆï¼Œè¿”å› {} ä¸ªå…ƒç´ çš„JSONæ•°æ®", count);
                    Ok(json_elements)
                }
                Err(e) => {
                    error!("âŒ åºåˆ—åŒ–ä¸ºJSONå¤±è´¥: {}", e);
                    Err(format!("åºåˆ—åŒ–ä¸ºJSONå¤±è´¥: {}", e))
                }
            }
        }
        Err(e) => {
            error!("âŒ è§£æXMLå¤±è´¥: {}", e);
            Err(format!("è§£æXMLå¤±è´¥: {}", e))
        }
    }
}

fn get_debug_xml_dir() -> std::path::PathBuf {
    // ğŸ”§ ä¿®å¤ï¼šå¼ºåˆ¶ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•çš„ç»å¯¹è·¯å¾„ï¼Œé¿å…è¿è¡Œæ—¶è·¯å¾„æ··ä¹±
    let absolute_project_root = std::path::PathBuf::from("D:\\rust\\active-projects\\å°çº¢ä¹¦\\employeeGUI");
    let debug_xml_path = absolute_project_root.join("debug_xml");
    
    // è®°å½•è°ƒè¯•ä¿¡æ¯
    info!("ğŸ” XMLç¼“å­˜ç›®å½•æ£€æŸ¥:");
    info!("  - å½“å‰å·¥ä½œç›®å½•: {:?}", std::env::current_dir().unwrap_or_default());
    info!("  - é€‰æ‹©çš„debug_xmlè·¯å¾„: {}", debug_xml_path.display());
    info!("  - è·¯å¾„æ˜¯å¦å­˜åœ¨: {}", debug_xml_path.exists());
    
    debug_xml_path
}

/// ğŸ”§ è°ƒè¯•å‘½ä»¤ï¼šæ£€æŸ¥XMLç¼“å­˜è·¯å¾„é—®é¢˜
#[tauri::command]
async fn debug_xml_cache_paths() -> Result<serde_json::Value, String> {
    use std::fs;
    use serde_json::json;
    
    let current_dir = std::env::current_dir().unwrap_or_else(|_| std::path::PathBuf::from("."));
    let debug_dir = get_debug_xml_dir();
    
    // æ£€æŸ¥å¤šä¸ªå¯èƒ½çš„è·¯å¾„
    let paths_to_check = vec![
        current_dir.join("debug_xml"),
        current_dir.parent().unwrap_or(&current_dir).join("debug_xml"),
        std::path::PathBuf::from("D:\\rust\\active-projects\\å°çº¢ä¹¦\\employeeGUI\\debug_xml"),
    ];
    
    let mut path_results = Vec::new();
    
    for path in &paths_to_check {
        let exists = path.exists();
        let file_count = if exists {
            fs::read_dir(&path)
                .map(|entries| entries.filter_map(|e| e.ok()).count())
                .unwrap_or(0)
        } else {
            0
        };
        
        path_results.push(json!({
            "path": path.to_string_lossy(),
            "exists": exists,
            "file_count": file_count,
            "is_current_choice": path == &debug_dir
        }));
    }
    
    Ok(json!({
        "current_working_directory": current_dir.to_string_lossy(),
        "chosen_debug_xml_dir": debug_dir.to_string_lossy(),
        "debug_xml_dir_exists": debug_dir.exists(),
        "all_paths_checked": path_results
    }))
}

// ==================== ğŸ”® Analysis Cache Management ====================

/// å°†æ­¥éª¤ä¸XMLå¿«ç…§å…³è”ï¼Œå¢åŠ å¼•ç”¨è®¡æ•°
#[tauri::command]
#[allow(unused_variables)]
async fn link_step_snapshot(
    step_id: String,
    snapshot_id: SnapshotId,
    description: Option<String>
) -> Result<usize, String> {
    let _ = description;
    debug!(
        step_id = %step_id,
        snapshot_id = %snapshot_id,
        "Linking step to snapshot"
    );
    
    match pin_snapshot(&snapshot_id, Some(&step_id)) {
        Ok(ref_count) => {
            info!(
                step_id = %step_id,
                snapshot_id = %snapshot_id,
                new_ref_count = ref_count,
                "Successfully linked step to snapshot"
            );
            Ok(ref_count)
        }
        Err(e) => {
            error!(
                step_id = %step_id,
                snapshot_id = %snapshot_id,
                error = %e,
                "Failed to link step to snapshot"
            );
            Err(format!("é“¾æ¥æ­¥éª¤åˆ°å¿«ç…§å¤±è´¥: {}", e))
        }
    }
}

/// è§£é™¤æ­¥éª¤ä¸XMLå¿«ç…§å…³è”ï¼Œå‡å°‘å¼•ç”¨è®¡æ•°
#[tauri::command]
async fn unlink_step_snapshot(
    step_id: String,
    snapshot_id: SnapshotId,
    force_remove: Option<bool>
) -> Result<Option<usize>, String> {
    let force = force_remove.unwrap_or(false);
    
    debug!(
        step_id = %step_id,
        snapshot_id = %snapshot_id,
        force_remove = force,
        "Unlinking step from snapshot"
    );
    
    match unpin_snapshot(&snapshot_id, Some(&step_id), force) {
        Ok(remaining_count) => {
            info!(
                step_id = %step_id,
                snapshot_id = %snapshot_id,
                remaining_count = ?remaining_count,
                force_remove = force,
                "Successfully unlinked step from snapshot"
            );
            Ok(remaining_count)
        }
        Err(e) => {
            error!(
                step_id = %step_id,
                snapshot_id = %snapshot_id,
                error = %e,
                "Failed to unlink step from snapshot"
            );
            Err(format!("è§£é™¤æ­¥éª¤å¿«ç…§å…³è”å¤±è´¥: {}", e))
        }
    }
}

/// è·å–æŒ‡å®šå¿«ç…§çš„å¼•ç”¨ä¿¡æ¯
#[tauri::command]
async fn get_snapshot_reference_info(snapshot_id: SnapshotId) -> Result<Option<SnapshotRefInfo>, String> {
    debug!(snapshot_id = %snapshot_id, "Getting snapshot reference info");
    
    let info = get_snapshot_ref_info(&snapshot_id);
    
    if let Some(ref info) = info {
        debug!(
            snapshot_id = %snapshot_id,
            ref_count = info.ref_count,
            "Found snapshot reference info"
        );
    } else {
        debug!(snapshot_id = %snapshot_id, "No reference info found for snapshot");
    }
    
    Ok(info)
}

/// è·å–æ‰€æœ‰å¿«ç…§çš„å¼•ç”¨è®¡æ•°ç»Ÿè®¡
#[tauri::command]
async fn get_all_snapshot_references() -> Result<HashMap<SnapshotId, usize>, String> {
    debug!("Getting all snapshot references");
    
    let refs = get_all_snapshot_refs();
    
    info!(
        total_snapshots = refs.len(),
        "Retrieved all snapshot references"
    );
    
    Ok(refs)
}

/// è·å–ç¼“å­˜ç³»ç»Ÿæ•´ä½“çŠ¶æ€
#[derive(Serialize)]
pub struct CacheSystemStatus {
    pub dom_cache_size: usize,
    pub subtree_cache_size: usize,
    pub reference_count: usize,
    pub total_references: usize,
    pub consistency_issues: Vec<String>,
}

#[tauri::command]
async fn get_cache_system_status() -> Result<CacheSystemStatus, String> {
    debug!("Getting cache system status");
    
    let consistency_issues = validate_cache_consistency()
        .map_err(|e| format!("ç¼“å­˜ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥: {}", e))?;
    
    let all_refs = get_all_snapshot_refs();
    let total_references: usize = all_refs.values().sum();
    
    let status = CacheSystemStatus {
        dom_cache_size: DOM_CACHE.len(),
        subtree_cache_size: SUBTREE_CACHE.len(),
        reference_count: SNAPSHOT_REFS.len(),
        total_references,
        consistency_issues,
    };
    
    info!(
        dom_cache_size = status.dom_cache_size,
        subtree_cache_size = status.subtree_cache_size,
        reference_count = status.reference_count,
        total_references = status.total_references,
        issues_found = status.consistency_issues.len(),
        "Cache system status retrieved"
    );
    
    Ok(status)
}

/// éªŒè¯ç¼“å­˜ä¸€è‡´æ€§
#[tauri::command]
async fn validate_cache_consistency_cmd() -> Result<Vec<String>, String> {
    debug!("Validating cache consistency");
    
    match validate_cache_consistency() {
        Ok(issues) => {
            if issues.is_empty() {
                info!("Cache consistency validation passed - no issues found");
            } else {
                warn!(
                    issues_count = issues.len(),
                    "Cache consistency validation found issues"
                );
            }
            Ok(issues)
        }
        Err(e) => {
            error!(error = %e, "Cache consistency validation failed");
            Err(format!("ç¼“å­˜ä¸€è‡´æ€§éªŒè¯å¤±è´¥: {}", e))
        }
    }
}

/// å¼ºåˆ¶æ¸…ç†æ‰€æœ‰ç¼“å­˜ï¼ˆè°ƒè¯•ç”¨ï¼‰
#[tauri::command]
async fn force_clear_all_caches_cmd() -> Result<(), String> {
    warn!("Force clearing all caches - this is a debug operation");
    
    match force_clear_all_caches() {
        Ok(()) => {
            info!("Successfully force cleared all caches");
            Ok(())
        }
        Err(e) => {
            error!(error = %e, "Failed to force clear caches");
            Err(format!("å¼ºåˆ¶æ¸…ç†ç¼“å­˜å¤±è´¥: {}", e))
        }
    }
}

/// æ¸…ç†è¿‡æœŸç¼“å­˜
#[tauri::command]
async fn cleanup_cache_cmd(max_age_hours: u32) -> Result<usize, String> {
    // TODO: å®ç°åŸºäºæ—¶é—´çš„ç¼“å­˜æ¸…ç†
    tracing::info!("ç¼“å­˜æ¸…ç†: æœ€å¤§å¹´é¾„{}å°æ—¶", max_age_hours);
    Ok(0)
}

// ==================== ğŸ§  Analysis Cache Commands (from analysis_cache.rs) ====================

/// æ³¨å†ŒXMLå¿«ç…§ï¼Œè¿”å›SnapshotId
#[tauri::command]
async fn register_snapshot_cmd(xml_content: String) -> String {
    let snapshot_id = register_snapshot(&xml_content);
    tracing::info!("å‰ç«¯æ³¨å†ŒXMLå¿«ç…§: snapshot_id={}", snapshot_id);
    snapshot_id
}

/// è·å–å­æ ‘åˆ†ææŒ‡æ ‡
#[tauri::command]
async fn get_subtree_metrics_cmd(
    snapshot_id: String,
    abs_xpath: String,
) -> Result<SubtreeMetricsDto, String> {
    match get_or_compute_subtree(&snapshot_id, &abs_xpath) {
        Ok(metrics) => {
            tracing::debug!("å‰ç«¯è·å–å­æ ‘æŒ‡æ ‡: xpath={}, ç­–ç•¥={}", 
                          abs_xpath, metrics.suggested_strategy);
            Ok(metrics.into())
        }
        Err(e) => {
            tracing::error!("è·å–å­æ ‘æŒ‡æ ‡å¤±è´¥: {}", e);
            Err(e.to_string())
        }
    }
}

/// å°è¯•ä»ç¼“å­˜è·å–å­æ ‘æŒ‡æ ‡ï¼ˆä¸è§¦å‘è®¡ç®—ï¼‰
#[tauri::command]
async fn try_get_subtree_metrics_cmd(
    snapshot_id: String,
    abs_xpath: String,
) -> Option<SubtreeMetricsDto> {
    try_get_subtree(&snapshot_id, &abs_xpath).map(|m| m.into())
}

/// æ‰¹é‡è·å–å¤šä¸ªå…ƒç´ çš„å­æ ‘æŒ‡æ ‡
#[tauri::command]
async fn batch_get_subtree_metrics_cmd(
    snapshot_id: String,
    xpath_list: Vec<String>,
) -> Result<Vec<SubtreeMetricsDto>, String> {
    let mut results = Vec::new();
    
    for abs_xpath in xpath_list {
        match get_or_compute_subtree(&snapshot_id, &abs_xpath) {
            Ok(metrics) => results.push(metrics.into()),
            Err(e) => {
                tracing::warn!("æ‰¹é‡è·å–æŒ‡æ ‡å¤±è´¥: xpath={}, error={}", abs_xpath, e);
                return Err(format!("è·å–{}æŒ‡æ ‡å¤±è´¥: {}", abs_xpath, e));
            }
        }
    }
    
    tracing::info!("æ‰¹é‡è·å–å®Œæˆ: å¤„ç†{}ä¸ªå…ƒç´ ", results.len());
    Ok(results)
}

#[derive(serde::Serialize)]
pub struct CacheStats {
    pub dom_cache_size: usize,
    pub subtree_cache_size: usize,
    pub total_memory_mb: usize,
}

/// è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
#[tauri::command]
async fn get_cache_stats_cmd() -> CacheStats {
    use crate::domain::analysis_cache::{DOM_CACHE, SUBTREE_CACHE};
    
    let stats = CacheStats {
        dom_cache_size: DOM_CACHE.len(),
        subtree_cache_size: SUBTREE_CACHE.len(),
        total_memory_mb: 0, // TODO: å®é™…è®¡ç®—å†…å­˜ä½¿ç”¨
    };
    
    tracing::debug!("ç¼“å­˜ç»Ÿè®¡: DOM={}, å­æ ‘={}", 
                   stats.dom_cache_size, stats.subtree_cache_size);
    
    stats
}

// ==================== ğŸ”Œ Plugin Initialization ====================

pub fn init<R: Runtime>() -> TauriPlugin<R> {
    Builder::new("xml_cache")
        .invoke_handler(tauri::generate_handler![
            // XML Cache
            list_xml_cache_files,
            list_xml_cache_files_with_metadata, // ğŸš€ æ–°å¢ï¼šæ‰¹é‡è·å–å…ƒæ•°æ®
            read_xml_cache_file,
            get_xml_file_size,
            get_xml_file_absolute_path,
            delete_xml_cache_artifacts,
            parse_cached_xml_to_elements,
            debug_xml_cache_paths,
            
            // Enhanced Cache
            enhanced::enhanced_cache_file_exists,
            enhanced::get_enhanced_cache_stats,
            enhanced::cleanup_enhanced_cache,
            enhanced::clear_all_enhanced_cache,
            enhanced::read_enhanced_cache_file,
            enhanced::save_enhanced_cache_file,
            enhanced::get_enhanced_cache_metadata,
            enhanced::clear_enhanced_cache_directory,
            enhanced::delete_enhanced_cache_file,

            // Analysis Cache
            link_step_snapshot,
            unlink_step_snapshot,
            get_snapshot_reference_info,
            get_all_snapshot_references,
            get_cache_system_status,
            validate_cache_consistency_cmd,
            force_clear_all_caches_cmd,
            register_snapshot_cmd,
            get_subtree_metrics_cmd,
            try_get_subtree_metrics_cmd,
            batch_get_subtree_metrics_cmd,
            cleanup_cache_cmd,
            get_cache_stats_cmd
        ])
        .build()
}
