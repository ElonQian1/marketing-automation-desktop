// src/modules/structural-matching/ui/hooks/use-parameter-inference-status.ts
// module: structural-matching | layer: ui | role: å‚æ•°æ¨ç†çŠ¶æ€ç®¡ç†Hook
// summary: ç®¡ç†å’Œè·Ÿè¸ªæ­¥éª¤å¡ç‰‡å‚æ•°æ¨ç†çŠ¶æ€çš„React Hook

import { useState, useEffect, useCallback } from 'react';
import { useStepCardStore } from '../../../../store/stepcards';
import { 
  RuntimeInferenceResult,
  RuntimeInferenceStatus,
  defaultRuntimeInferenceService 
} from '../../services/step-card-parameter-inference/runtime-parameter-inference-service';

export interface ParameterInferenceHookResult {
  /** æ¨ç†ç»“æœ */
  inferenceResult: RuntimeInferenceResult | null;
  
  /** æ¨ç†çŠ¶æ€ */
  status: RuntimeInferenceStatus;
  
  /** æ˜¯å¦æ­£åœ¨æ¨ç† */
  isInferring: boolean;
  
  /** æ¨ç†é”™è¯¯ */
  error: string | null;
  
  /** æ‰‹åŠ¨è§¦å‘æ¨ç† */
  triggerInference: () => Promise<void>;
  
  /** æ¸…é™¤æ¨ç†ç»“æœ */
  clearInference: () => void;
  
  /** åˆ·æ–°çŠ¶æ€ */
  refresh: () => void;
}

/**
 * å‚æ•°æ¨ç†çŠ¶æ€ç®¡ç†Hook
 * 
 * @param stepCardId æ­¥éª¤å¡ç‰‡ID
 * @param autoRefresh æ˜¯å¦è‡ªåŠ¨åˆ·æ–°çŠ¶æ€
 * @returns æ¨ç†çŠ¶æ€å’Œæ§åˆ¶å‡½æ•°
 */
export function useParameterInferenceStatus(
  stepCardId: string,
  autoRefresh: boolean = true
): ParameterInferenceHookResult {
  const [inferenceResult, setInferenceResult] = useState<RuntimeInferenceResult | null>(null);
  const [isInferring, setIsInferring] = useState(false);
  const [error, setError] = useState<string | null>(null);
  
  const { cards, byStepId } = useStepCardStore();
  
  // è·å–å½“å‰æ­¥éª¤å¡ç‰‡
  const stepCard = byStepId[stepCardId] ? cards[byStepId[stepCardId]] : null;
  
  // ä»æ­¥éª¤å¡ç‰‡è·å–æ¨ç†çŠ¶æ€
  const getInferenceStatusFromStepCard = useCallback(() => {
    if (!stepCard) {
      return 'disabled' as RuntimeInferenceStatus;
    }
    
    // æ£€æŸ¥æ˜¯å¦å·²æœ‰ç»“æ„åŒ¹é…å‚æ•°
    if (stepCard.structuralMatchPlan) {
      return 'not_needed' as RuntimeInferenceStatus;
    }
    
    // æ£€æŸ¥æ¨ç†çŠ¶æ€
    if (stepCard.inferenceState) {
      return stepCard.inferenceState.status as RuntimeInferenceStatus;
    }
    
    // æ£€æŸ¥æ˜¯å¦å¯ä»¥æ¨ç†
    return defaultRuntimeInferenceService.needsInference(stepCard) ? 
      'pending' as RuntimeInferenceStatus : 
      'disabled' as RuntimeInferenceStatus;
  }, [stepCard]);

  const status = getInferenceStatusFromStepCard();

  // æ‰‹åŠ¨è§¦å‘æ¨ç†
  const triggerInference = useCallback(async () => {
    if (!stepCard || isInferring) {
      return;
    }
    
    try {
      setIsInferring(true);
      setError(null);
      
      console.log(`ğŸ§  [Hook] å¼€å§‹ä¸ºæ­¥éª¤å¡ç‰‡ ${stepCardId} æ¨ç†å‚æ•°`);
      
      const result = await defaultRuntimeInferenceService.inferParametersForStepCard(stepCard);
      
      setInferenceResult(result);
      
      if (result.status === 'failed') {
        setError(result.error || 'æ¨ç†å¤±è´¥');
      }
      
      console.log(`ğŸ§  [Hook] æ­¥éª¤å¡ç‰‡ ${stepCardId} æ¨ç†å®Œæˆ:`, result.status);
      
    } catch (err) {
      const errorMsg = err instanceof Error ? err.message : String(err);
      setError(errorMsg);
      console.error(`âŒ [Hook] æ­¥éª¤å¡ç‰‡ ${stepCardId} æ¨ç†å‡ºé”™:`, errorMsg);
    } finally {
      setIsInferring(false);
    }
  }, [stepCard, stepCardId, isInferring]);

  // æ¸…é™¤æ¨ç†ç»“æœ
  const clearInference = useCallback(() => {
    setInferenceResult(null);
    setError(null);
    setIsInferring(false);
  }, []);

  // åˆ·æ–°çŠ¶æ€
  const refresh = useCallback(() => {
    if (stepCard?.inferenceState) {
      // ä»æ­¥éª¤å¡ç‰‡æ„å»ºæ¨ç†ç»“æœ
      const result: RuntimeInferenceResult = {
        status: stepCard.inferenceState.status as RuntimeInferenceStatus,
        plan: stepCard.structuralMatchPlan,
        error: stepCard.inferenceState.error,
      };
      setInferenceResult(result);
      
      if (result.error) {
        setError(result.error);
      }
    }
  }, [stepCard]);

  // è‡ªåŠ¨åˆ·æ–°çŠ¶æ€
  useEffect(() => {
    if (autoRefresh) {
      refresh();
    }
  }, [autoRefresh, refresh, stepCard?.inferenceState, stepCard?.structuralMatchPlan]);

  return {
    inferenceResult,
    status,
    isInferring,
    error,
    triggerInference,
    clearInference,
    refresh,
  };
}

/**
 * æ‰¹é‡å‚æ•°æ¨ç†çŠ¶æ€ç®¡ç†Hook
 * 
 * @param stepCardIds æ­¥éª¤å¡ç‰‡IDåˆ—è¡¨
 * @returns æ‰¹é‡æ¨ç†çŠ¶æ€
 */
export function useBatchParameterInferenceStatus(stepCardIds: string[]) {
  const [batchResults, setBatchResults] = useState<Record<string, RuntimeInferenceResult>>({});
  const [isInferring, setIsInferring] = useState(false);
  const [progress, setProgress] = useState(0);
  
  const { cards, byStepId } = useStepCardStore();

  // æ‰¹é‡æ¨ç†
  const triggerBatchInference = useCallback(async () => {
    if (isInferring) return;
    
    try {
      setIsInferring(true);
      setProgress(0);
      
      const results: Record<string, RuntimeInferenceResult> = {};
      
      for (let i = 0; i < stepCardIds.length; i++) {
        const stepCardId = stepCardIds[i];
        const stepCard = byStepId[stepCardId] ? cards[byStepId[stepCardId]] : null;
        
        if (stepCard) {
          console.log(`ğŸ§  [æ‰¹é‡æ¨ç†] å¤„ç†æ­¥éª¤ ${i + 1}/${stepCardIds.length}: ${stepCardId}`);
          
          try {
            const result = await defaultRuntimeInferenceService.inferParametersForStepCard(stepCard);
            results[stepCardId] = result;
          } catch (error) {
            results[stepCardId] = {
              status: 'failed',
              error: error instanceof Error ? error.message : String(error),
            };
          }
        }
        
        // æ›´æ–°è¿›åº¦
        setProgress(((i + 1) / stepCardIds.length) * 100);
      }
      
      setBatchResults(results);
      
      console.log(`âœ… [æ‰¹é‡æ¨ç†] å®Œæˆæ‰¹é‡æ¨ç†ï¼Œå¤„ç†äº† ${Object.keys(results).length} ä¸ªæ­¥éª¤`);
      
    } catch (error) {
      console.error('âŒ [æ‰¹é‡æ¨ç†] æ‰¹é‡æ¨ç†å¤±è´¥:', error);
    } finally {
      setIsInferring(false);
      setProgress(100);
    }
  }, [stepCardIds, cards, byStepId, isInferring]);

  // è·å–æ‰¹é‡çŠ¶æ€ç»Ÿè®¡
  const getStatusSummary = useCallback(() => {
    const results = Object.values(batchResults);
    return {
      total: results.length,
      completed: results.filter(r => r.status === 'completed').length,
      failed: results.filter(r => r.status === 'failed').length,
      pending: results.filter(r => r.status === 'pending').length,
      notNeeded: results.filter(r => r.status === 'not_needed').length,
    };
  }, [batchResults]);

  return {
    batchResults,
    isInferring,
    progress,
    triggerBatchInference,
    statusSummary: getStatusSummary(),
  };
}